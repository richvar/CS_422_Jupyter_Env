
Training options:
{
  "num_gpus": 1,
  "image_snapshot_ticks": 1,
  "network_snapshot_ticks": 1,
  "metrics": [],
  "random_seed": 0,
  "kimg_per_tick": 10,
  "training_set_kwargs": {
    "class_name": "training.dataset.ImageFolderDataset",
    "path": "./datasets/post-impressionist",
    "use_labels": false,
    "max_size": 2969,
    "xflip": false,
    "resolution": 512
  },
  "data_loader_kwargs": {
    "pin_memory": true,
    "num_workers": 1,
    "prefetch_factor": 2
  },
  "G_kwargs": {
    "class_name": "training.networks.Generator",
    "z_dim": 512,
    "w_dim": 512,
    "mapping_kwargs": {
      "num_layers": 2
    },
    "synthesis_kwargs": {
      "channel_base": 32768,
      "channel_max": 512,
      "num_fp16_res": 4,
      "conv_clamp": 256
    }
  },
  "D_kwargs": {
    "class_name": "training.networks.Discriminator",
    "block_kwargs": {},
    "mapping_kwargs": {},
    "epilogue_kwargs": {
      "mbstd_group_size": 4
    },
    "channel_base": 32768,
    "channel_max": 512,
    "num_fp16_res": 4,
    "conv_clamp": 256
  },
  "G_opt_kwargs": {
    "class_name": "torch.optim.Adam",
    "lr": 0.0025,
    "betas": [
      0,
      0.99
    ],
    "eps": 1e-08
  },
  "D_opt_kwargs": {
    "class_name": "torch.optim.Adam",
    "lr": 0.0025,
    "betas": [
      0,
      0.99
    ],
    "eps": 1e-08
  },
  "loss_kwargs": {
    "class_name": "training.loss.StyleGAN2Loss",
    "r1_gamma": 6.5536
  },
  "total_kimg": 25000,
  "batch_size": 8,
  "batch_gpu": 8,
  "ema_kimg": 2.5,
  "ema_rampup": null,
  "ada_target": 0.6,
  "augment_kwargs": {
    "class_name": "training.augment.AugmentPipe",
    "xflip": 1,
    "rotate90": 1,
    "xint": 1,
    "scale": 1,
    "rotate": 1,
    "aniso": 1,
    "xfrac": 1,
    "brightness": 1,
    "contrast": 1,
    "lumaflip": 1,
    "hue": 1,
    "saturation": 1
  },
  "resume_pkl": "./results/00006-post-impressionist-auto1-ada-resumecustom/network-snapshot-001100.pkl",
  "ada_kimg": 100,
  "run_dir": "./results/00008-post-impressionist-auto1-ada-resumecustom"
}

Output directory:   ./results/00008-post-impressionist-auto1-ada-resumecustom
Training data:      ./datasets/post-impressionist
Training duration:  25000 kimg
Number of GPUs:     1
Number of images:   2969
Image resolution:   512
Conditional model:  False
Dataset x-flips:    False

Creating output directory...
Launching processes...
Loading training set...

Num images:  2969
Image shape: [3, 512, 512]
Label shape: [0]

Constructing networks...
Resuming from "./results/00006-post-impressionist-auto1-ada-resumecustom/network-snapshot-001100.pkl"
Setting up PyTorch plugin "bias_act_plugin"... Done.
Setting up PyTorch plugin "upfirdn2d_plugin"... Done.

Generator             Parameters  Buffers  Output shape        Datatype
---                   ---         ---      ---                 ---     
mapping.fc0           262656      -        [8, 512]            float32 
mapping.fc1           262656      -        [8, 512]            float32 
mapping               -           512      [8, 16, 512]        float32 
synthesis.b4.conv1    2622465     32       [8, 512, 4, 4]      float32 
synthesis.b4.torgb    264195      -        [8, 3, 4, 4]        float32 
synthesis.b4:0        8192        16       [8, 512, 4, 4]      float32 
synthesis.b4:1        -           -        [8, 512, 4, 4]      float32 
synthesis.b8.conv0    2622465     80       [8, 512, 8, 8]      float32 
synthesis.b8.conv1    2622465     80       [8, 512, 8, 8]      float32 
synthesis.b8.torgb    264195      -        [8, 3, 8, 8]        float32 
synthesis.b8:0        -           16       [8, 512, 8, 8]      float32 
synthesis.b8:1        -           -        [8, 512, 8, 8]      float32 
synthesis.b16.conv0   2622465     272      [8, 512, 16, 16]    float32 
synthesis.b16.conv1   2622465     272      [8, 512, 16, 16]    float32 
synthesis.b16.torgb   264195      -        [8, 3, 16, 16]      float32 
synthesis.b16:0       -           16       [8, 512, 16, 16]    float32 
synthesis.b16:1       -           -        [8, 512, 16, 16]    float32 
synthesis.b32.conv0   2622465     1040     [8, 512, 32, 32]    float32 
synthesis.b32.conv1   2622465     1040     [8, 512, 32, 32]    float32 
synthesis.b32.torgb   264195      -        [8, 3, 32, 32]      float32 
synthesis.b32:0       -           16       [8, 512, 32, 32]    float32 
synthesis.b32:1       -           -        [8, 512, 32, 32]    float32 
synthesis.b64.conv0   2622465     4112     [8, 512, 64, 64]    float16 
synthesis.b64.conv1   2622465     4112     [8, 512, 64, 64]    float16 
synthesis.b64.torgb   264195      -        [8, 3, 64, 64]      float16 
synthesis.b64:0       -           16       [8, 512, 64, 64]    float16 
synthesis.b64:1       -           -        [8, 512, 64, 64]    float32 
synthesis.b128.conv0  1442561     16400    [8, 256, 128, 128]  float16 
synthesis.b128.conv1  721409      16400    [8, 256, 128, 128]  float16 
synthesis.b128.torgb  132099      -        [8, 3, 128, 128]    float16 
synthesis.b128:0      -           16       [8, 256, 128, 128]  float16 
synthesis.b128:1      -           -        [8, 256, 128, 128]  float32 
synthesis.b256.conv0  426369      65552    [8, 128, 256, 256]  float16 
synthesis.b256.conv1  213249      65552    [8, 128, 256, 256]  float16 
synthesis.b256.torgb  66051       -        [8, 3, 256, 256]    float16 
synthesis.b256:0      -           16       [8, 128, 256, 256]  float16 
synthesis.b256:1      -           -        [8, 128, 256, 256]  float32 
synthesis.b512.conv0  139457      262160   [8, 64, 512, 512]   float16 
synthesis.b512.conv1  69761       262160   [8, 64, 512, 512]   float16 
synthesis.b512.torgb  33027       -        [8, 3, 512, 512]    float16 
synthesis.b512:0      -           16       [8, 64, 512, 512]   float16 
synthesis.b512:1      -           -        [8, 64, 512, 512]   float32 
---                   ---         ---      ---                 ---     
Total                 28700647    699904   -                   -       


Discriminator  Parameters  Buffers  Output shape        Datatype
---            ---         ---      ---                 ---     
b512.fromrgb   256         16       [8, 64, 512, 512]   float16 
b512.skip      8192        16       [8, 128, 256, 256]  float16 
b512.conv0     36928       16       [8, 64, 512, 512]   float16 
b512.conv1     73856       16       [8, 128, 256, 256]  float16 
b512           -           16       [8, 128, 256, 256]  float16 
b256.skip      32768       16       [8, 256, 128, 128]  float16 
b256.conv0     147584      16       [8, 128, 256, 256]  float16 
b256.conv1     295168      16       [8, 256, 128, 128]  float16 
b256           -           16       [8, 256, 128, 128]  float16 
b128.skip      131072      16       [8, 512, 64, 64]    float16 
b128.conv0     590080      16       [8, 256, 128, 128]  float16 
b128.conv1     1180160     16       [8, 512, 64, 64]    float16 
b128           -           16       [8, 512, 64, 64]    float16 
b64.skip       262144      16       [8, 512, 32, 32]    float16 
b64.conv0      2359808     16       [8, 512, 64, 64]    float16 
b64.conv1      2359808     16       [8, 512, 32, 32]    float16 
b64            -           16       [8, 512, 32, 32]    float16 
b32.skip       262144      16       [8, 512, 16, 16]    float32 
b32.conv0      2359808     16       [8, 512, 32, 32]    float32 
b32.conv1      2359808     16       [8, 512, 16, 16]    float32 
b32            -           16       [8, 512, 16, 16]    float32 
b16.skip       262144      16       [8, 512, 8, 8]      float32 
b16.conv0      2359808     16       [8, 512, 16, 16]    float32 
b16.conv1      2359808     16       [8, 512, 8, 8]      float32 
b16            -           16       [8, 512, 8, 8]      float32 
b8.skip        262144      16       [8, 512, 4, 4]      float32 
b8.conv0       2359808     16       [8, 512, 8, 8]      float32 
b8.conv1       2359808     16       [8, 512, 4, 4]      float32 
b8             -           16       [8, 512, 4, 4]      float32 
b4.mbstd       -           -        [8, 513, 4, 4]      float32 
b4.conv        2364416     16       [8, 512, 4, 4]      float32 
b4.fc          4194816     -        [8, 512]            float32 
b4.out         513         -        [8, 1]              float32 
---            ---         ---      ---                 ---     
Total          28982849    480      -                   -       

Setting up augmentation...
Distributing across 1 GPUs...
Setting up training phases...
Exporting sample images...
Initializing logs...
Skipping tfevents export: No module named 'tensorboard'
Training for 25000 kimg...

tick 0     kimg 0.0      time 10m 02s      sec/tick 10.7    sec/kimg 1340.77 maintenance 591.7  cpumem 6.10   gpumem 14.76  augment 0.000
tick 1     kimg 10.0     time 24m 28s      sec/tick 846.3   sec/kimg 84.63   maintenance 19.7   cpumem 6.19   gpumem 7.28   augment 0.086
tick 2     kimg 20.0     time 38m 54s      sec/tick 848.8   sec/kimg 84.88   maintenance 16.8   cpumem 6.23   gpumem 7.26   augment 0.165
tick 3     kimg 30.0     time 53m 29s      sec/tick 850.1   sec/kimg 85.01   maintenance 24.6   cpumem 6.20   gpumem 7.35   augment 0.225
tick 4     kimg 40.0     time 1h 07m 57s   sec/tick 851.4   sec/kimg 85.14   maintenance 16.8   cpumem 6.20   gpumem 7.30   augment 0.268
tick 5     kimg 50.0     time 1h 22m 23s   sec/tick 851.5   sec/kimg 85.15   maintenance 14.2   cpumem 6.20   gpumem 7.32   augment 0.292
tick 6     kimg 60.0     time 1h 36m 54s   sec/tick 852.5   sec/kimg 85.25   maintenance 19.1   cpumem 6.20   gpumem 7.35   augment 0.318
tick 7     kimg 70.0     time 1h 51m 23s   sec/tick 853.0   sec/kimg 85.30   maintenance 16.1   cpumem 6.20   gpumem 7.37   augment 0.329
tick 8     kimg 80.0     time 2h 05m 53s   sec/tick 853.4   sec/kimg 85.34   maintenance 16.1   cpumem 6.20   gpumem 7.45   augment 0.337
tick 9     kimg 90.0     time 2h 20m 25s   sec/tick 853.1   sec/kimg 85.31   maintenance 19.1   cpumem 6.23   gpumem 7.38   augment 0.351
tick 10    kimg 100.0    time 2h 34m 58s   sec/tick 853.2   sec/kimg 85.32   maintenance 19.8   cpumem 6.21   gpumem 7.41   augment 0.353
tick 11    kimg 110.0    time 2h 49m 26s   sec/tick 852.8   sec/kimg 85.28   maintenance 14.7   cpumem 6.21   gpumem 7.36   augment 0.361
tick 12    kimg 120.0    time 3h 03m 57s   sec/tick 853.4   sec/kimg 85.34   maintenance 18.3   cpumem 6.21   gpumem 7.39   augment 0.363
tick 13    kimg 130.0    time 3h 18m 32s   sec/tick 852.5   sec/kimg 85.25   maintenance 22.5   cpumem 6.23   gpumem 7.37   augment 0.358
tick 14    kimg 140.0    time 3h 33m 04s   sec/tick 852.6   sec/kimg 85.26   maintenance 19.3   cpumem 6.21   gpumem 7.42   augment 0.356
tick 15    kimg 150.0    time 3h 47m 34s   sec/tick 853.0   sec/kimg 85.30   maintenance 16.4   cpumem 6.21   gpumem 7.41   augment 0.364
tick 16    kimg 160.0    time 4h 02m 05s   sec/tick 853.8   sec/kimg 85.38   maintenance 17.4   cpumem 6.21   gpumem 7.39   augment 0.368
tick 17    kimg 170.0    time 4h 16m 35s   sec/tick 853.1   sec/kimg 85.31   maintenance 16.6   cpumem 6.21   gpumem 7.39   augment 0.373
tick 18    kimg 180.0    time 4h 31m 05s   sec/tick 853.4   sec/kimg 85.34   maintenance 16.6   cpumem 6.21   gpumem 7.40   augment 0.369
tick 19    kimg 190.0    time 4h 45m 30s   sec/tick 853.0   sec/kimg 85.30   maintenance 12.1   cpumem 6.21   gpumem 7.43   augment 0.370
tick 20    kimg 200.0    time 4h 59m 56s   sec/tick 852.7   sec/kimg 85.27   maintenance 13.5   cpumem 6.25   gpumem 7.39   augment 0.372
tick 21    kimg 210.0    time 5h 14m 21s   sec/tick 852.7   sec/kimg 85.27   maintenance 12.0   cpumem 6.21   gpumem 7.40   augment 0.371
tick 22    kimg 220.0    time 5h 28m 44s   sec/tick 853.2   sec/kimg 85.32   maintenance 10.6   cpumem 6.21   gpumem 7.39   augment 0.381
tick 23    kimg 230.0    time 5h 43m 09s   sec/tick 853.8   sec/kimg 85.38   maintenance 10.9   cpumem 6.21   gpumem 7.41   augment 0.372
tick 24    kimg 240.0    time 5h 57m 36s   sec/tick 853.4   sec/kimg 85.34   maintenance 14.0   cpumem 6.21   gpumem 7.36   augment 0.372
tick 25    kimg 250.0    time 6h 12m 18s   sec/tick 868.8   sec/kimg 86.88   maintenance 13.2   cpumem 6.25   gpumem 7.38   augment 0.363
tick 26    kimg 260.0    time 6h 27m 24s   sec/tick 893.3   sec/kimg 89.33   maintenance 12.1   cpumem 6.21   gpumem 7.51   augment 0.362
tick 27    kimg 270.0    time 6h 44m 01s   sec/tick 984.0   sec/kimg 98.40   maintenance 13.5   cpumem 6.20   gpumem 7.38   augment 0.365
tick 28    kimg 280.0    time 6h 59m 46s   sec/tick 931.3   sec/kimg 93.13   maintenance 13.9   cpumem 6.20   gpumem 7.38   augment 0.366
tick 29    kimg 290.0    time 7h 14m 14s   sec/tick 856.1   sec/kimg 85.61   maintenance 11.9   cpumem 6.20   gpumem 7.44   augment 0.367
tick 30    kimg 300.0    time 7h 28m 42s   sec/tick 854.3   sec/kimg 85.43   maintenance 12.9   cpumem 6.20   gpumem 7.43   augment 0.371
tick 31    kimg 310.0    time 7h 43m 07s   sec/tick 852.8   sec/kimg 85.28   maintenance 12.5   cpumem 6.22   gpumem 7.40   augment 0.370
tick 32    kimg 320.0    time 7h 57m 33s   sec/tick 852.8   sec/kimg 85.28   maintenance 13.1   cpumem 6.20   gpumem 7.43   augment 0.364
tick 33    kimg 330.0    time 8h 12m 00s   sec/tick 854.7   sec/kimg 85.47   maintenance 12.9   cpumem 6.20   gpumem 7.43   augment 0.366
tick 34    kimg 340.0    time 8h 26m 30s   sec/tick 857.2   sec/kimg 85.72   maintenance 12.3   cpumem 6.29   gpumem 7.45   augment 0.370
tick 35    kimg 350.0    time 8h 40m 59s   sec/tick 856.0   sec/kimg 85.60   maintenance 12.7   cpumem 6.32   gpumem 7.41   augment 0.376
tick 36    kimg 360.0    time 8h 55m 22s   sec/tick 853.1   sec/kimg 85.31   maintenance 10.6   cpumem 6.34   gpumem 7.48   augment 0.377
tick 37    kimg 370.0    time 9h 09m 47s   sec/tick 852.9   sec/kimg 85.29   maintenance 11.6   cpumem 6.34   gpumem 7.40   augment 0.375
tick 38    kimg 380.0    time 9h 24m 12s   sec/tick 853.0   sec/kimg 85.30   maintenance 12.4   cpumem 6.23   gpumem 7.59   augment 0.377
tick 39    kimg 390.0    time 9h 38m 38s   sec/tick 853.3   sec/kimg 85.33   maintenance 11.9   cpumem 6.32   gpumem 7.39   augment 0.377
tick 40    kimg 400.0    time 9h 53m 04s   sec/tick 853.5   sec/kimg 85.35   maintenance 12.6   cpumem 6.20   gpumem 7.49   augment 0.378
