üì• Loading Inception model...
üì• Loading real images...
üßÆ Computing real image features...

üîç Evaluating snapshot 100 kimg: /home/s25vargason1/richard/512_basic_training/stylegan2-ada-pytorch/results/00008-post-impressionist-auto1-ada-resumecustom/network-snapshot-000100.pkl
üñºÔ∏è Generating 4000 fake images...
Setting up PyTorch plugin "bias_act_plugin"... Done.
Setting up PyTorch plugin "upfirdn2d_plugin"... Done.
Traceback (most recent call last):
  File "/home/s25vargason1/fid_calc/fid_calc.py", line 96, in <module>
    img = G(z=z, c=c, truncation_psi=1.0, noise_mode='const')
  File "/home/s25vargason1/miniconda3/envs/venv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "<string>", line 499, in forward
  File "/home/s25vargason1/miniconda3/envs/venv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "<string>", line 471, in forward
  File "/home/s25vargason1/miniconda3/envs/venv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "<string>", line 406, in forward
  File "/home/s25vargason1/miniconda3/envs/venv/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "<string>", line 299, in forward
  File "/home/s25vargason1/richard/512_basic_training/stylegan2-ada-pytorch/torch_utils/misc.py", line 101, in decorator
    return fn(*args, **kwargs)
  File "<string>", line 65, in modulated_conv2d
  File "/home/s25vargason1/richard/512_basic_training/stylegan2-ada-pytorch/torch_utils/misc.py", line 101, in decorator
    return fn(*args, **kwargs)
  File "/home/s25vargason1/richard/512_basic_training/stylegan2-ada-pytorch/torch_utils/ops/conv2d_resample.py", line 147, in conv2d_resample
    return _conv2d_wrapper(x=x, w=w, padding=[py0,px0], groups=groups, flip_weight=flip_weight)
  File "/home/s25vargason1/richard/512_basic_training/stylegan2-ada-pytorch/torch_utils/ops/conv2d_resample.py", line 54, in _conv2d_wrapper
    return op(x, w, stride=stride, padding=padding, groups=groups)
  File "/home/s25vargason1/richard/512_basic_training/stylegan2-ada-pytorch/torch_utils/ops/conv2d_gradfix.py", line 38, in conv2d
    return torch.nn.functional.conv2d(input=input, weight=weight, bias=bias, stride=stride, padding=padding, dilation=dilation, groups=groups)
RuntimeError: CUDA out of memory. Tried to allocate 256.00 MiB (GPU 0; 23.50 GiB total capacity; 10.00 GiB already allocated; 231.38 MiB free; 10.87 GiB reserved in total by PyTorch)
srun: error: gpu002: task 0: Exited with exit code 1
